{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ML4EO LAB5\n","## Transfer Learning"],"metadata":{"id":"oTJOCg67QfAj"}},{"cell_type":"markdown","source":["## Importing necessary packages"],"metadata":{"id":"ai7B30OMl3ae"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import cv2\n","from glob import glob\n","import os\n","import pandas as pd\n","from sklearn.utils import shuffle\n","import random\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"3y7NZPzdl9Cl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# devices\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"Device: \", device)"],"metadata":{"id":"nQoQ-onWmmtI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Getting dataset"],"metadata":{"id":"9IF0G9iNnRJ5"}},{"cell_type":"markdown","source":["Link to the dataset:  https://drive.google.com/drive/folders/1-CCSBRiMvnNQFMvaSdi110vlM7mk2pbP?usp=sharing\n"],"metadata":{"id":"QmRnKsofmqg8"}},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Z0B2U9dFYwW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify the path to your image\n","file_path = \"/content/drive/MyDrive/NCST-YieldPrediction/RwandaDroneImagery/imagery/_modeling/train/banana/2564_Feb2019.png\"\n","\n","# Open the image\n","image = Image.open(file_path)\n","\n","# Display the image\n","plt.imshow(image)\n","plt.axis('off')  # Turn off axis numbers\n","plt.show()"],"metadata":{"id":"Hq7PXWr5YwTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_images_in_directory(directory_path):\n","    \"\"\"\n","    This function is used to\n","    count the number of image files in each subdirectory of the given directory(train as well validation set).\n","    and itr also help to returns the total count of images in the whole sets.\n","    \"\"\"\n","    # Supported image extension\n","    image_extensions = ['.png']\n","\n","    total_image_count = 0\n","\n","    # Iterate over each subdirectory in the main directory\n","    for subdirectory in os.listdir(directory_path):\n","        sub_dir_path = os.path.join(directory_path, subdirectory)\n","\n","        # Make sure it's a directory\n","        if os.path.isdir(sub_dir_path):\n","            image_count = 0\n","\n","            # Count image files\n","            for filename in os.listdir(sub_dir_path):\n","                if any(filename.endswith(ext) for ext in image_extensions):\n","                    image_count += 1\n","\n","            print(f'Number of images in \"{subdirectory}\" of {os.path.basename(directory_path)}: {image_count}')\n","            total_image_count += image_count\n","\n","    return total_image_count\n","\n","# Main train directory paths\n","train_dir_path = '/content/drive/MyDrive/NCST-YieldPrediction/RwandaDroneImagery/imagery/_modeling/train'\n","total_train_images = count_images_in_directory(train_dir_path)\n","print(f'\\nTotal number of images in training: {total_train_images}')"],"metadata":{"id":"5InUnLcXYwMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main test directory paths\n","test_dir_path = '/content/drive/MyDrive/NCST-YieldPrediction/RwandaDroneImagery/imagery/_modeling/test'\n","total_test_images = count_images_in_directory(test_dir_path)\n","print(f'\\nTotal number of images in training: {total_test_images}')"],"metadata":{"id":"4sJePKycY9h-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataframe_with_labels(directory_path):\n","    \"\"\"\n","    This fucntion help to make a dataframe so that all the images we have will be put together in a dataframe\n","    with their corresponding lables\n","    \"\"\"\n","    image_extensions = ['.png']\n","    data = {'Image': [], 'label_name': []}\n","\n","    for subdirectory in os.listdir(directory_path):\n","        sub_dir_path = os.path.join(directory_path, subdirectory)\n","        if os.path.isdir(sub_dir_path):\n","            for filename in os.listdir(sub_dir_path):\n","                if any(filename.endswith(ext) for ext in image_extensions):\n","                    image_path = os.path.join(sub_dir_path, filename)\n","                    data['Image'].append(image_path)\n","                    data['label_name'].append(subdirectory)  # Subdirectory name as label\n","\n","    return pd.DataFrame(data)"],"metadata":{"id":"Ttwe4fkMY9ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create train dataframes\n","train_df = create_dataframe_with_labels(train_dir_path)\n","train_df.sample(10) # Print datasamples from dataframes"],"metadata":{"id":"60fjg6JyY9ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create dataframes\n","test_df = create_dataframe_with_labels(test_dir_path)\n","test_df.sample(10) # Print datasamples from dataframes"],"metadata":{"id":"oPYqWrRFnBm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_images(column_name, df):\n","    \"\"\"\n","    This function helps to make a plot of different crop types in the dataset\n","    to view their characteristics\n","    \"\"\"\n","    sample_df = df.sample(12, random_state = 0)\n","    # Create subplots\n","    fig, axes = plt.subplots(2, 6, figsize=(12, 4))\n","    # Iterate over the subplots\n","    for i, ax in enumerate(axes.flat):\n","        image_file_path = sample_df.iloc[i][column_name]\n","        image = Image.open(image_file_path)\n","        # Get the label name from the DataFrame\n","        label_name = sample_df.iloc[i][\"Label\"]\n","\n","        # Plot the image and put labels\n","        ax.imshow(image)\n","        ax.set_title(label_name)\n","        ax.axis(\"off\")\n","\n","    # Display the plot\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"eGm3zrowMVrw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_dict = {'legumes': 0,\n"," 'maize': 1,\n"," 'banana': 2,\n"," 'forest': 3,\n"," 'other': 4,\n"," 'structure': 5}"],"metadata":{"id":"MUpp9fhMaEX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encode labels\n","train_df[\"label\"] = [labels_dict[label] for label in train_df.label_name.values]\n","test_df[\"label\"] = [labels_dict[label] for label in test_df.label_name.values]"],"metadata":{"id":"IaixuXCtaEUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting into traing and test dataset\n","training_df, validation_df = train_test_split(train_df, test_size=0.2, random_state=42)\n"],"metadata":{"id":"32_aAUe-aERw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_imgs, test_labels = test_df[\"Image\"], test_df[\"label\"]"],"metadata":{"id":"DMx0i5D0aEPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting into traing and test dataset\n","train_imgs, val_imgs, train_labels, val_labels = training_df[\"Image\"], validation_df[\"Image\"], training_df[\"label\"], validation_df[\"label\"]\n","\n","\n","assert len(train_imgs)==len(train_labels), 'Not equal'\n","\n","len(train_imgs), len(val_imgs)"],"metadata":{"id":"pjUXFDOCQ0Ur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_imgs=pd.DataFrame(test_imgs).reset_index(drop=True)\n","test_labels=pd.DataFrame(test_labels).reset_index(drop=True)"],"metadata":{"id":"Jhiq0IpCiFhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_imgs=pd.DataFrame(train_imgs).reset_index(drop=True)\n","val_imgs=pd.DataFrame(val_imgs).reset_index(drop=True)\n","train_labels=pd.DataFrame(train_labels).reset_index(drop=True)\n","val_labels=pd.DataFrame(val_labels).reset_index(drop=True)\n","train_imgs"],"metadata":{"id":"hstH2ZegWGvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's visualize\n"],"metadata":{"id":"HAG2pF6dSrF0"}},{"cell_type":"code","source":["random_idx = np.random.randint(low=0,high=len(train_imgs)-1,size=6)\n","random_idx"],"metadata":{"id":"o7metJSxSuNS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classes\n","labels_dict"],"metadata":{"id":"TIY8BQtyJJWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","nrows=2\n","ncols=3\n","fig, ax=plt.subplots(nrows=nrows, ncols=ncols,figsize=(10,8))\n","i=0\n","for row in range(0,nrows):\n","    for col in range(0,ncols):\n","        img=cv2.imread(train_imgs[\"Image\"][random_idx[i]])\n","        ax[row][col].imshow(img)\n","        ax[row][col].set_title(f'{img.shape}->{train_labels[\"label\"][random_idx[i]]}')\n","        ax[row][col].axis(False)\n","        i+=1\n"],"metadata":{"id":"8lPuXS6QUbY9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset preparation  and building a data loader"],"metadata":{"id":"zRjcu-vRd-4i"}},{"cell_type":"code","source":["class TrainDataset(Dataset):\n","    def __init__(self, img_list, label_list):\n","        self.img_s = img_list\n","        self.label_s = label_list\n","\n","    def __len__(self):\n","        return len(self.img_s)\n","\n","    def __getitem__(self, idx):\n","        image = self.img_s[idx]\n","        label = self.label_s[idx]\n","\n","        image = torch.from_numpy(cv2.imread(image))\n","\n","        image = image.permute(2,0,1)\n","\n","\n","        return image, label"],"metadata":{"id":"_Ny-ulEHd-GC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ValDataset(Dataset):\n","    def __init__(self, img_list, label_list):\n","        self.img_s = img_list\n","        self.label_s = label_list\n","\n","    def __len__(self):\n","        return len(self.img_s)\n","\n","    def __getitem__(self, idx):\n","        image = self.img_s[idx]\n","        label = self.label_s[idx]\n","\n","        image = torch.from_numpy(cv2.imread(image))\n","\n","        image = image.permute(2,0,1)\n","\n","\n","        return image, label"],"metadata":{"id":"Ll-T4q9j6jGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating data\n","Train_data = TrainDataset(train_imgs[\"Image\"],train_labels[\"label\"])\n","val_data = ValDataset(val_imgs[\"Image\"],val_labels[\"label\"])\n","f\"Len of train dataset: {len(Train_data)}->shape of image at idx 0: {Train_data[0][0].shape}->Label:{Train_data[0][1]}\""],"metadata":{"id":"b8wC7PwNgHTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = ValDataset(test_imgs[\"Image\"], test_labels['label'])"],"metadata":{"id":"e9dMcPd0iWSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch = 32"],"metadata":{"id":"dYwYZlDkiziZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loader = DataLoader(\n","    dataset     = test_data,\n","    batch_size  = batch,\n","    shuffle     = False\n",")"],"metadata":{"id":"ZUsyfOYxio7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data loading\n","train_loader = DataLoader(\n","    dataset     = Train_data,\n","    batch_size  = batch,\n","    shuffle     = True\n",")\n","\n","val_loader = DataLoader(\n","    dataset     = val_data,\n","    batch_size  = batch,\n","    shuffle     = False\n",")"],"metadata":{"id":"MI3Joy_Jg3d5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check data loaders\n","f\"Train batchs: {len(train_loader)}, Test batches: {len(val_loader)}\""],"metadata":{"id":"I9KBs0a7i8zT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, data in enumerate(train_loader):\n","    img, labels = data\n","    print(img.shape, labels.shape)\n","    break"],"metadata":{"id":"uY6aB27Ija0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, data in enumerate(val_loader):\n","    img,labels = data\n","    print(img.shape,labels.shape)\n","    break"],"metadata":{"id":"LCsPsN9kjtDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.models import vgg16"],"metadata":{"id":"T23KNBCRcQXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg16 = vgg16(pretrained=True)\n","vgg16"],"metadata":{"id":"YtvdiWdccQTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_size = 25088\n","classifier = nn.Sequential(nn.Flatten(), nn.Linear(input_size, 512), nn.Sigmoid(), nn.Dropout(p=0.2), nn.Linear(512, 6), nn.Softmax(dim=1))"],"metadata":{"id":"Om5vqFXGcoIz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg16.classifier=classifier\n","vgg16"],"metadata":{"id":"4G6C7sn2cQRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model =vgg16.to(device)"],"metadata":{"id":"nkGAGP9Lc4p4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Let's check the model output"],"metadata":{"id":"mnp-y43SOGc_"}},{"cell_type":"code","source":["# Get the batch to test the model\n","one_batch = next(iter(train_loader))\n","my_batch = one_batch[0].to(device)\n","my_batch.shape,my_batch.dtype"],"metadata":{"id":"u6S_HVTIOfkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing the model with a single batch\n","model(my_batch.float())"],"metadata":{"id":"cEbFbEo6R6Pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print model outputs to see the shapes at each layer\n","\n","try:\n","  import torchinfo\n","except:\n","  !pip install torchinfo\n","  import torchinfo\n","\n","from torchinfo import summary\n","summary(model,input_size=(1,3,200,200))"],"metadata":{"id":"-wCeSZKOS1nQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's check number of trainable parameters\n","\n","params=[par_um.numel() for par_um in model.parameters() if par_um.requires_grad==True]\n","sum(params)"],"metadata":{"id":"9gm48vQlYghv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ready to train our model"],"metadata":{"id":"8WNTNt-Ga0BL"}},{"cell_type":"code","source":["# For optimer and loss function\n","import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.CrossEntropyLoss()\n","scheduler =optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.95)"],"metadata":{"id":"TwrLWrcHagWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, dataloader, optimizer, criterion):\n","\n","    model.train()\n","\n","    # Progress Bar\n","    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n","\n","    num_correct = 0\n","    total_loss  = 0\n","\n","    for batch_idx, (images, target) in enumerate(dataloader):\n","\n","        optimizer.zero_grad() # Zero gradients\n","\n","        images, target = images.to(device), target.to(device)\n","\n","\n","        outputs = model(images.float())\n","        loss    = criterion(outputs, target)\n","\n","        # Update correct predictions & loss\n","        num_correct     += int((torch.argmax(outputs.cpu(), axis=1) == target.cpu()).sum())\n","        total_loss      += float(loss.item())\n","\n","        # tqdm - adding info to be checked on the progress bar\n","        batch_bar.set_postfix(\n","            acc         = f\"{(100 * num_correct / (batch*(batch_idx + 1))):.04f}%\",\n","            loss        = f\"{total_loss / (batch_idx + 1):.04f}\",\n","            num_correct = num_correct,\n","            lr          = f\"{optimizer.param_groups[0]['lr']:.04f}\"\n","        )\n","\n","        batch_bar.update() # Update tqdm bar\n","\n","    batch_bar.close() # close the tqdm bar after each epoch\n","\n","    acc         = 100 * num_correct / (batch* len(dataloader))\n","    total_loss  = float(total_loss / len(dataloader))\n","\n","    return acc, total_loss"],"metadata":{"id":"46fNhbVIQCl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","\n","    model.eval()\n","    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n","\n","    num_correct = 0.0\n","    total_loss = 0.0\n","\n","    for batch_idx, (images, target) in enumerate(dataloader):\n","\n","        # Move images to device\n","        images, target = images.to(device), target.to(device)\n","\n","        # Get model outputs\n","        with torch.inference_mode():\n","            outputs = model(images.float())\n","            loss = criterion(outputs, target)\n","\n","        num_correct += int((torch.argmax(outputs.cpu(), axis=1) == target.cpu()).sum())\n","        total_loss += float(loss.item())\n","\n","        batch_bar.set_postfix(\n","            acc=\"{:.04f}%\".format(100 * num_correct / (batch*(batch_idx + 1))),\n","            loss=\"{:.04f}\".format(float(total_loss / (batch_idx + 1))),\n","            num_correct=num_correct)\n","\n","        batch_bar.update()\n","\n","    batch_bar.close()\n","    acc = 100 * num_correct / (batch* len(dataloader))\n","    total_loss = float(total_loss / len(dataloader))\n","    return acc, total_loss"],"metadata":{"id":"VwCs4d50Spsk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_valAcc = 0.0 # Initialize the accuracy to help saving the best model\n","\n","Epochs = 5\n","for epoch in range(Epochs):\n","\n","    curr_lr = float(optimizer.param_groups[0]['lr'])\n","\n","    train_acc, train_loss = train(model, train_loader, optimizer, criterion)\n","\n","    print(\"\\nEpoch {}/{}: \\nTrain Acc {:.04f}%\\t Train Loss {:.04f}\\t Learning Rate {:.04f}\".format(\n","        epoch + 1,\n","        Epochs,\n","        train_acc,\n","        train_loss,\n","        curr_lr))\n","\n","    val_acc, val_loss = validate(model, val_loader, criterion)\n","\n","    print(\"Val Acc {:.04f}%\\t Val Loss {:.04f}\".format(val_acc, val_loss))\n","\n","    # learning rate scheduler, update\n","    scheduler.step()\n","\n","    # Save the best model based on accuracy\n","    if val_acc >= best_valAcc:\n","\n","        path = '/content/drive/MyDrive/RwandaDroneImagery/checkpoint.pth'\n","        print(\"Saving model\")\n","        torch.save({'model_state_dict':model.state_dict(),\n","                  'optimizer_state_dict':optimizer.state_dict(),\n","                  'scheduler_state_dict':scheduler.state_dict(),\n","                  'val_acc': val_acc,\n","                  'epoch': epoch}, path)\n","        best_valAcc = val_acc\n","\n","\n"],"metadata":{"id":"BrWOx53xYVGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","true_labels = []\n","predicted_labels = []\n","total_loss  = 0\n","\n","for i, (images, labels) in enumerate(test_loader):\n","\n","    images, labels = images.to(device), labels.to(device)\n","    outputs = model(images.float())\n","\n","    # Store true labels and predicted labels for F1-score calculation\n","    true_labels.extend(labels.cpu().numpy())\n","    predicted_labels.extend(torch.argmax(outputs, axis=1).cpu().numpy())\n"],"metadata":{"id":"KlghOHBsgDCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inv_labels_dict = {0: 'legumes', 1: 'maize', 2: 'banana', 3: 'forest', 4: 'other', 5: 'structure'}"],"metadata":{"id":"U7dYZkIAgFgF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score\n","import numpy as np\n","\n","\n","# Compute classification report\n","report = classification_report(true_labels, predicted_labels, target_names=np.unique(true_labels), output_dict=True)\n","\n","# Create a dictionary to hold evaluation metrics per class\n","metrics_per_class = {}\n","for class_name, metrics in report.items():\n","    if class_name != 'accuracy' and class_name != 'macro avg' and class_name != 'weighted avg':\n","        metrics_per_class[inv_labels_dict[class_name]] = {\n","            'F1 Score': metrics['f1-score'],\n","            'Precision': metrics['precision'],\n","            'Recall': metrics['recall'],\n","\n","        }\n","\n","# Add overall metrics\n","metrics_per_class['Overall'] = {\n","    'F1 Score': report['macro avg']['f1-score'],\n","    'Precision': report['macro avg']['precision'],\n","    'Recall': report['macro avg']['recall'],\n","\n","\n","}\n","\n","# Print the table\n","print(\"| {:<10} | {:<9} | {:<9} | {:<6} |\".format(\"Class\", \"F1 Score\", \"Precision\", \"Recall\"))\n","print(\"|\" + \"-\"*12 + \"|\" + \"-\"*11 + \"|\" + \"-\"*11 + \"|\" + \"-\"*8 + \"|\")\n","for class_name, metrics in metrics_per_class.items():\n","    print(\"| {:<10} | {:<9.2f} | {:<9.2f} | {:<6.2f} |\".format(class_name,\n","                                                                                      metrics['F1 Score'],\n","                                                                                      metrics['Precision'],\n","                                                                                      metrics['Recall'],\n","                                                                                      ))\n"],"metadata":{"id":"CTQSeCtygHLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ToDO\n","Discuss the benefits (5marks) and limitations (5marks) of transfer learning in deep learning applications"],"metadata":{"id":"JqrFIF7QyjE-"}},{"cell_type":"code","source":[],"metadata":{"id":"kLta_8Ixv0Pj"},"execution_count":null,"outputs":[]}]}